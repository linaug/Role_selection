framework: torch
env: path_planning
lambda: 0.95
kl_coeff: 0.5
kl_target: 0.01
clip_rewards: True
clip_param: 0.2
vf_clip_param: 250.0
vf_share_layers: False
vf_loss_coeff: 1.0e-4
entropy_coeff: 0.01
train_batch_size: 5000
rollout_fragment_length: 100
sgd_minibatch_size: 1000
num_sgd_iter: 5
num_workers: 7
num_envs_per_worker: 16
lr: 4.0e-4
gamma: 0.99
batch_mode: complete_episodes
observation_filter: NoFilter
num_gpus: 1.0
model:
    custom_model: adversarial
    custom_action_dist: hom_multi_action
    custom_model_config:
        graph_layers: 1
        graph_tabs: 2
        graph_edge_features: 1
        graph_features: 128
        cnn_filters: [[8, [4, 4], 2], [16, [4, 4], 2], [32, [3, 3], 2]]
        value_cnn_filters: [[16, [4, 4], 2], [32, [4, 4], 2]]
        value_cnn_compression: 128
        cnn_compression: 32
        gp_kernel_size: 16
        graph_aggregation: sum
        activation: relu
        freeze_coop: False
        freeze_greedy: False
        freeze_coop_value: False
        freeze_greedy_value: False
        cnn_residual: False
        agent_split: 1
env_config:
    world_shape: [12, 12]
    state_size: 16
    max_episode_len: 50
    n_agents: [1, 15]
    disabled_teams_step: [True, False]
    disabled_teams_comms: [True, False]
    communication_range: 5.0
    ensure_connectivity: True
    reward_type: coop_only
    world_mode: warehouse
    agents:
        visibility_distance: 0
        relative_coord_frame: True
evaluation_num_workers: 1
evaluation_interval: 1
evaluation_num_episodes: 10
evaluation_config:
    env_config:
        reward_type: local
alternative_config:
    self_interested:
        env_config:
            reward_type: greedy_only
            disabled_teams_step: [False, False]
            disabled_teams_comms: [False, False]
        model:
            custom_model_config:
                freeze_coop: True
                freeze_greedy: False
        evaluation_config:
            env_config:
                reward_type: local
    re_adapt:
        env_config:
            reward_type: coop_only
            disabled_teams_step: [False, False]
            disabled_teams_comms: [False, False]
        model:
            custom_model_config:
                freeze_coop: False
                freeze_greedy: True
        evaluation_config:
            env_config:
                reward_type: local
